{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VargheseTito/NYC-Taxi-Trip-Time-Prediction/blob/main/NYC_Taxi_Trip_Time_Prediction_(Loud_n_Cloud)_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Taxi trip time Prediction : Predicting total ride duration of taxi trips in New York City</u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### Your task is to build a model that predicts the total ride duration of taxi trips in New York City. Your primary dataset is one released by the NYC Taxi and Limousine Commission, which includes pickup time, geo-coordinates, number of passengers, and several other variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWeU1f9bwqQq"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### The dataset is based on the 2016 NYC Yellow Cab trip record data made available in Big Query on Google Cloud Platform. The data was originally published by the NYC Taxi and Limousine Commission (TLC). The data was sampled and cleaned for the purposes of this project. Based on individual trip attributes, you should predict the duration of each trip in the test set.\n",
        "\n",
        "### <b>NYC Taxi Data.csv</b> - the training set (contains 1458644 trip records)\n",
        "\n",
        "\n",
        "### Data fields\n",
        "* #### id - a unique identifier for each trip\n",
        "* #### vendor_id - a code indicating the provider associated with the trip record\n",
        "* #### pickup_datetime - date and time when the meter was engaged\n",
        "* #### dropoff_datetime - date and time when the meter was disengaged\n",
        "* #### passenger_count - the number of passengers in the vehicle (driver entered value)\n",
        "* #### pickup_longitude - the longitude where the meter was engaged\n",
        "* #### pickup_latitude - the latitude where the meter was engaged\n",
        "* #### dropoff_longitude - the longitude where the meter was disengaged\n",
        "* #### dropoff_latitude - the latitude where the meter was disengaged\n",
        "* #### store_and_fwd_flag - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip\n",
        "* #### trip_duration - duration of the trip in seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ5_pSeeCRTu"
      },
      "source": [
        "#Introduction\n",
        "This is our Regression Capstone Project,hence we will be looking into multiple regression models and try to come up with a best model at the end of this project. We are only focussing on all that algorithm which has been taught to us till now in our class. \n",
        "SVM,Time Series, Clustering and many more algos. still yet to be taught to us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx1hnX2NDfwr"
      },
      "source": [
        "#ML Pipeline to be followed \n",
        "\n",
        "1. Basic  Dataset Understanding(Dimensionality,records,Data Types,5-point summary)\n",
        "2.Data Preprocessing\n",
        "3. Data Cleaning\n",
        "4. Exploratory Data Analysis\n",
        "5. Feature Engineering\n",
        "6. Feature Selection\n",
        "7. Model Buliding\n",
        "8. Evaluation\n",
        "9. Hyperparameter tuning/cross Validation\n",
        "10.Conclusions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U6cGMv6AyRbw"
      },
      "outputs": [],
      "source": [
        "#Importing all the required libraries\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from numpy import math\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from datetime import datetime\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y6qOnCqIePfl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx1FXO1VyTTr",
        "outputId": "73af0512-861c-4f8a-9266-612ed0d7ac00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mounting the Drive inorder to load the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "outputs": [],
      "source": [
        "#Reading the csv dataset\n",
        "df=pd.read_csv('/content/drive/MyDrive/NYC Taxi Trip (Supervised ML Regression)-Tito Varghese/NYC Taxi Data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYB0sdRwFSjH"
      },
      "source": [
        "#1.Basic Dataset Understanding(Dimensionality,records,Data Types,5-point summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbIgvQ_szNFb",
        "outputId": "9ddcacae-6d55-4292-87f9-8230807985bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1458644 entries, 0 to 1458643\n",
            "Data columns (total 11 columns):\n",
            " #   Column              Non-Null Count    Dtype  \n",
            "---  ------              --------------    -----  \n",
            " 0   id                  1458644 non-null  object \n",
            " 1   vendor_id           1458644 non-null  int64  \n",
            " 2   pickup_datetime     1458644 non-null  object \n",
            " 3   dropoff_datetime    1458644 non-null  object \n",
            " 4   passenger_count     1458644 non-null  int64  \n",
            " 5   pickup_longitude    1458644 non-null  float64\n",
            " 6   pickup_latitude     1458644 non-null  float64\n",
            " 7   dropoff_longitude   1458644 non-null  float64\n",
            " 8   dropoff_latitude    1458644 non-null  float64\n",
            " 9   store_and_fwd_flag  1458644 non-null  object \n",
            " 10  trip_duration       1458644 non-null  int64  \n",
            "dtypes: float64(4), int64(3), object(4)\n",
            "memory usage: 122.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqaZzFaIny63"
      },
      "source": [
        "The dataset info tells us that the dataset contains 1458644 records and 11 columns.Out of 11 columns,4 columns are object datatype ,4 columns are float datatype and remaing 3 columns are integer datatype.\n",
        "\n",
        "The dataset doesn't contain any null values in any of the columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "u9_EYu--zOu6",
        "outputId": "212eb9ca-d327-43c6-db98-b20fc2be5c34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          vendor_id  passenger_count  pickup_longitude  pickup_latitude  \\\n",
              "count  1.458644e+06     1.458644e+06      1.458644e+06     1.458644e+06   \n",
              "mean   1.534950e+00     1.664530e+00     -7.397349e+01     4.075092e+01   \n",
              "std    4.987772e-01     1.314242e+00      7.090186e-02     3.288119e-02   \n",
              "min    1.000000e+00     0.000000e+00     -1.219333e+02     3.435970e+01   \n",
              "25%    1.000000e+00     1.000000e+00     -7.399187e+01     4.073735e+01   \n",
              "50%    2.000000e+00     1.000000e+00     -7.398174e+01     4.075410e+01   \n",
              "75%    2.000000e+00     2.000000e+00     -7.396733e+01     4.076836e+01   \n",
              "max    2.000000e+00     9.000000e+00     -6.133553e+01     5.188108e+01   \n",
              "\n",
              "       dropoff_longitude  dropoff_latitude  trip_duration  \n",
              "count       1.458644e+06      1.458644e+06   1.458644e+06  \n",
              "mean       -7.397342e+01      4.075180e+01   9.594923e+02  \n",
              "std         7.064327e-02      3.589056e-02   5.237432e+03  \n",
              "min        -1.219333e+02      3.218114e+01   1.000000e+00  \n",
              "25%        -7.399133e+01      4.073588e+01   3.970000e+02  \n",
              "50%        -7.397975e+01      4.075452e+01   6.620000e+02  \n",
              "75%        -7.396301e+01      4.076981e+01   1.075000e+03  \n",
              "max        -6.133553e+01      4.392103e+01   3.526282e+06  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdf52d15-7486-45dc-b81e-42fef9642651\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vendor_id</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>trip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.458644e+06</td>\n",
              "      <td>1.458644e+06</td>\n",
              "      <td>1.458644e+06</td>\n",
              "      <td>1.458644e+06</td>\n",
              "      <td>1.458644e+06</td>\n",
              "      <td>1.458644e+06</td>\n",
              "      <td>1.458644e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.534950e+00</td>\n",
              "      <td>1.664530e+00</td>\n",
              "      <td>-7.397349e+01</td>\n",
              "      <td>4.075092e+01</td>\n",
              "      <td>-7.397342e+01</td>\n",
              "      <td>4.075180e+01</td>\n",
              "      <td>9.594923e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.987772e-01</td>\n",
              "      <td>1.314242e+00</td>\n",
              "      <td>7.090186e-02</td>\n",
              "      <td>3.288119e-02</td>\n",
              "      <td>7.064327e-02</td>\n",
              "      <td>3.589056e-02</td>\n",
              "      <td>5.237432e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.219333e+02</td>\n",
              "      <td>3.435970e+01</td>\n",
              "      <td>-1.219333e+02</td>\n",
              "      <td>3.218114e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-7.399187e+01</td>\n",
              "      <td>4.073735e+01</td>\n",
              "      <td>-7.399133e+01</td>\n",
              "      <td>4.073588e+01</td>\n",
              "      <td>3.970000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-7.398174e+01</td>\n",
              "      <td>4.075410e+01</td>\n",
              "      <td>-7.397975e+01</td>\n",
              "      <td>4.075452e+01</td>\n",
              "      <td>6.620000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>-7.396733e+01</td>\n",
              "      <td>4.076836e+01</td>\n",
              "      <td>-7.396301e+01</td>\n",
              "      <td>4.076981e+01</td>\n",
              "      <td>1.075000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>9.000000e+00</td>\n",
              "      <td>-6.133553e+01</td>\n",
              "      <td>5.188108e+01</td>\n",
              "      <td>-6.133553e+01</td>\n",
              "      <td>4.392103e+01</td>\n",
              "      <td>3.526282e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdf52d15-7486-45dc-b81e-42fef9642651')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdf52d15-7486-45dc-b81e-42fef9642651 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdf52d15-7486-45dc-b81e-42fef9642651');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jACywBqosO6"
      },
      "source": [
        "The describe function gives us a five - point summary of our numerical columns present in our dataset(min,25%,50%,75% and max details)\n",
        "\n",
        "Apart from that,it tells the mean and standard deviation values of all respective numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfAwvDZNo8uh",
        "outputId": "871dc59f-3584-445d-9661-c4fed1cb590f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1458644, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "bNUInYNEo-94",
        "outputId": "3829e527-f3be-43f3-a011-baee5243af05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
              "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
              "1  id2377394          1  2016-06-12 00:43:35  2016-06-12 00:54:38   \n",
              "2  id3858529          2  2016-01-19 11:35:24  2016-01-19 12:10:48   \n",
              "3  id3504673          2  2016-04-06 19:32:31  2016-04-06 19:39:40   \n",
              "4  id2181028          2  2016-03-26 13:30:55  2016-03-26 13:38:10   \n",
              "\n",
              "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
              "0                1        -73.982155        40.767937         -73.964630   \n",
              "1                1        -73.980415        40.738564         -73.999481   \n",
              "2                1        -73.979027        40.763939         -74.005333   \n",
              "3                1        -74.010040        40.719971         -74.012268   \n",
              "4                1        -73.973053        40.793209         -73.972923   \n",
              "\n",
              "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
              "0         40.765602                  N            455  \n",
              "1         40.731152                  N            663  \n",
              "2         40.710087                  N           2124  \n",
              "3         40.706718                  N            429  \n",
              "4         40.782520                  N            435  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f234e2f-bb58-4d8d-b08b-06e8eb8fdc9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>vendor_id</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>trip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id2875421</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-03-14 17:24:55</td>\n",
              "      <td>2016-03-14 17:32:30</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.982155</td>\n",
              "      <td>40.767937</td>\n",
              "      <td>-73.964630</td>\n",
              "      <td>40.765602</td>\n",
              "      <td>N</td>\n",
              "      <td>455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id2377394</td>\n",
              "      <td>1</td>\n",
              "      <td>2016-06-12 00:43:35</td>\n",
              "      <td>2016-06-12 00:54:38</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.980415</td>\n",
              "      <td>40.738564</td>\n",
              "      <td>-73.999481</td>\n",
              "      <td>40.731152</td>\n",
              "      <td>N</td>\n",
              "      <td>663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id3858529</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-19 11:35:24</td>\n",
              "      <td>2016-01-19 12:10:48</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.979027</td>\n",
              "      <td>40.763939</td>\n",
              "      <td>-74.005333</td>\n",
              "      <td>40.710087</td>\n",
              "      <td>N</td>\n",
              "      <td>2124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id3504673</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-04-06 19:32:31</td>\n",
              "      <td>2016-04-06 19:39:40</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.010040</td>\n",
              "      <td>40.719971</td>\n",
              "      <td>-74.012268</td>\n",
              "      <td>40.706718</td>\n",
              "      <td>N</td>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id2181028</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-03-26 13:30:55</td>\n",
              "      <td>2016-03-26 13:38:10</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.973053</td>\n",
              "      <td>40.793209</td>\n",
              "      <td>-73.972923</td>\n",
              "      <td>40.782520</td>\n",
              "      <td>N</td>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f234e2f-bb58-4d8d-b08b-06e8eb8fdc9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f234e2f-bb58-4d8d-b08b-06e8eb8fdc9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f234e2f-bb58-4d8d-b08b-06e8eb8fdc9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoHB1MNmp7aR",
        "outputId": "ca78890d-608c-4ce2-8a26-d1afd8a77a5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                     object\n",
              "vendor_id               int64\n",
              "pickup_datetime        object\n",
              "dropoff_datetime       object\n",
              "passenger_count         int64\n",
              "pickup_longitude      float64\n",
              "pickup_latitude       float64\n",
              "dropoff_longitude     float64\n",
              "dropoff_latitude      float64\n",
              "store_and_fwd_flag     object\n",
              "trip_duration           int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cyIoC7UswwY",
        "outputId": "d04f9cde-673c-4bc5-9a9d-c3cdba522d6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                    1458644\n",
              "vendor_id                   2\n",
              "pickup_datetime       1380222\n",
              "dropoff_datetime      1380377\n",
              "passenger_count            10\n",
              "pickup_longitude        23047\n",
              "pickup_latitude         45245\n",
              "dropoff_longitude       33821\n",
              "dropoff_latitude        62519\n",
              "store_and_fwd_flag          2\n",
              "trip_duration            7417\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9U2v56Hs44g"
      },
      "source": [
        "We see that id has 1458644 unique values which are equal to the number of rows in our dataset.\n",
        "\n",
        "There are 2 unique vendor ids.\n",
        "\n",
        "There are 10 unique passenger counts.\n",
        "\n",
        "There are 2 unique values for store_and_fwd_flag, that we also saw in the description of the variables, which are Y and N."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2yK4T4-yjLY"
      },
      "source": [
        "#2.Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHwsep5cwEax"
      },
      "source": [
        "Next we will add some features to the dataset and at the same time also remove the outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_xrfuhgps2k"
      },
      "source": [
        "#Converting the datatype of pickup date time and dropoff date time to datetime datatype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kGCc1sccpBEU"
      },
      "outputs": [],
      "source": [
        "df['pickup_datetime']= pd.to_datetime(df['pickup_datetime'])\n",
        "df['dropoff_datetime']= pd.to_datetime(df['dropoff_datetime'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLJnlTiosvGA"
      },
      "source": [
        "#Adding few new Features  into the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNxCjCIop8QC"
      },
      "source": [
        "#Now, let us extract and create new features from this datetime features we just created "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4G8292SlsiPs"
      },
      "outputs": [],
      "source": [
        "#Extract hour from pickup and dropoff datetime columns\n",
        "df['pickup_hour']=df['pickup_datetime'].dt.hour\n",
        "df['dropoff_hour']=df['dropoff_datetime'].dt.hour\n",
        "\n",
        "#Extract day from pickup and dropoff datetime columns\n",
        "df['pickup_day']=df['pickup_datetime'].dt.day_name()\n",
        "df['dropoff_day']=df['dropoff_datetime'].dt.day_name()\n",
        "\n",
        "#Extract date from pickup and dropoff datetime columns\n",
        "df['pickup_date']=pd.DatetimeIndex(df['pickup_datetime']).day\n",
        "df['dropoff_date']=pd.DatetimeIndex(df['dropoff_datetime']).day\n",
        "\n",
        "#Extract month from pickup and dropoff datetime columns\n",
        "df['pickup_month']=df['pickup_datetime'].dt.month\n",
        "df['dropoff_month']=df['dropoff_datetime'].dt.month\n",
        "\n",
        "#Extract weekday from pickup and dropoff datetime columns\n",
        "df['pickup_weekday']=df['pickup_datetime'].dt.weekday\n",
        "df['dropoff_weekday']=df['dropoff_datetime'].dt.weekday"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M45ocvZsgfY"
      },
      "source": [
        "pickup_day and dropoff_day which will contain the name of the day on which the ride was taken. \n",
        "\n",
        "pickup_weekday and dropoff_weekday which will contain the day number instead of characters with Monday=0 and Sunday=6. \n",
        "\n",
        "pickup_hour and dropoff_hour with an hour of the day in the 24-hour format. \n",
        "\n",
        "pickup_date and dropoff_date will provide the date of the trip.\n",
        "\n",
        "pickup_month and dropoff_month with month number with January=1 and December=12. Next, I have "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xFtCdDstMzW"
      },
      "source": [
        "#New feature created time_zone\n",
        "Defined a function that lets us determine what time of the day the ride was taken. I have created 4 time zones ‘Morning’ (from 6:00 am to 11:59 pm), ‘Afternoon’ (from 12 noon to 3:59 pm), ‘Evening’ (from 4:00 pm to 9:59 pm), and ‘Late Night’ (from 10:00 pm to 5:59 am)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YxB_G83Dsfi5"
      },
      "outputs": [],
      "source": [
        "def time_zone(x):\n",
        "    if x in range(6,12):\n",
        "        return 'Morning'\n",
        "    elif x in range(12,16):\n",
        "        return 'Afternoon'\n",
        "    elif x in range(16,22):\n",
        "        return 'Evening'\n",
        "    else:\n",
        "        return 'Late night'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KQDy4BEMuJEW"
      },
      "outputs": [],
      "source": [
        "df['pickup_timezone']=df['pickup_hour'].apply(time_zone)\n",
        "df['dropoff_timezone']=df['dropoff_hour'].apply(time_zone)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smo6OpP2uPcK"
      },
      "source": [
        "#New feature Created distance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqZQfATZvbSO"
      },
      "source": [
        "We also saw during dataset exploration that we have coordinates in the form of longitude and latitude for pickup and dropoff. But, we can’t really gather any insights or draw conclusions from that.\n",
        "So, the most obvious feature that we can extract from this is distance. Let us do that.\n",
        "\n",
        "Importing the library which lets us calculate distance from geographical coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rnFx9yocvb4x"
      },
      "outputs": [],
      "source": [
        "from geopy.distance import great_circle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6G0aYbpjvkrC"
      },
      "outputs": [],
      "source": [
        "def cal_distance(pickup_lat,pickup_long,dropoff_lat,dropoff_long):\n",
        " \n",
        " start_coordinates=(pickup_lat,pickup_long)\n",
        " stop_coordinates=(dropoff_lat,dropoff_long)\n",
        " \n",
        " return great_circle(start_coordinates,stop_coordinates).km"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Lf0twx4Uvofh"
      },
      "outputs": [],
      "source": [
        "df['distance'] = df.apply(lambda x: cal_distance(x['pickup_latitude'],x['pickup_longitude'],x['dropoff_latitude'],x['dropoff_longitude'] ), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyTc54l0DmSB"
      },
      "source": [
        "#New feature created trip direction \n",
        "\n",
        "It was observed, especially for the airport trips, that the direction of the trip also has some effect on the trip duration.\n",
        "\n",
        "Let's add the bearing of each trip which simply means the overall direction in which the taxi travelled from the pickup point to the dropoff point.\n",
        "\n",
        "The convention followed here is such the North is denoted as 0 degrees, East as 90 degrees, South as 180 degrees and circle back to North as 360 degrees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ItpKz10KLGLh"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def get_bearing(lat1, long1, lat2, long2):\n",
        "    dLon = (long2 - long1)\n",
        "    x = math.cos(math.radians(lat2)) * math.sin(math.radians(dLon))\n",
        "    y = math.cos(math.radians(lat1)) * math.sin(math.radians(lat2)) - math.sin(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.cos(math.radians(dLon))\n",
        "    brng = np.arctan2(x,y)\n",
        "    brng = np.degrees(brng)\n",
        "    if brng < 0:\n",
        "      brng = 360 + brng\n",
        "      return brng\n",
        "    else:\n",
        "      return brng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3RPdIEYLlhQ"
      },
      "outputs": [],
      "source": [
        "df['trip_direction'] = df.apply(lambda x: get_bearing(x['pickup_latitude'],x['pickup_longitude'],x['dropoff_latitude'], \n",
        "                       x['dropoff_longitude']), axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpgcSnff0u6o"
      },
      "source": [
        "#New Feature created trip_speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rfpY20w0-sv"
      },
      "outputs": [],
      "source": [
        "df['time_diff_minutes']= df['dropoff_datetime']- df['pickup_datetime']\n",
        "df['time_diff_minutes']= df['time_diff_minutes']/np.timedelta64(1,'m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdVFKlDP1HF3"
      },
      "outputs": [],
      "source": [
        "#The trip_speed unit will be mph\n",
        "def speed(x,y):\n",
        "  z = (x*0.621)/(y*0.016667)\n",
        "  return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSvBfPue1T-U"
      },
      "outputs": [],
      "source": [
        "df['trip_speed']= df.apply(lambda x: speed(x['distance'],x['time_diff_minutes']),axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuiqsL2Xv5Y5"
      },
      "source": [
        "#Thus, we successfully created some new features which we will analyze in univariate and bivariate analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY7yK8qjsMxB"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QN7knfiNMZL"
      },
      "source": [
        "#3.Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBj9zCkGts4f"
      },
      "outputs": [],
      "source": [
        "#Checking Missing Values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "let2QZU_wJHL"
      },
      "outputs": [],
      "source": [
        "#Checking Duplicated Rows\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_nBphJJBz7L"
      },
      "source": [
        "#Handling Outliers\n",
        "\n",
        "The pickup  latitudes and longitudes should be within the NYC boundary defined as\n",
        "pickup latitude/longitude < 1th percentile value of the pickup latitude/longitude and pickup latitude/longitude > 99.8th percentile value of the trip duration\n",
        "\n",
        "tripduration < 1th percentile value of the trip duration and trip_duration > 99.8th percentile value of the trip duration\n",
        "\n",
        "distance  between the pickup and dropoff points is > its 1th percentile value and < its 99.8th percentile value.\n",
        "\n",
        "trip_speed  between the pickup and dropoff points is > its 1th percentile value and < its 99.8th percentile value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzjbVFYvwt5v"
      },
      "source": [
        "Removing Outliers from Pickup_latitude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axmptKjo2bL3"
      },
      "source": [
        "Over here we will be take to consideration data records which lies between 99% and 1% range and consider records outside this range as outliers .Hence we will drop records which are outside the range from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pav80bUpvfYq"
      },
      "outputs": [],
      "source": [
        "percentile_speed = [1, 25, 50, 75, 95, 99, 99.8]\n",
        "print(\"Total number of trips = {:,}\".format(len(df)))\n",
        "for i in percentile_speed:\n",
        "    print(\"{}% of the latitude were below {:.2f} degree\".format(i, np.percentile(df.pickup_latitude, i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzQT2nuLkjmE"
      },
      "outputs": [],
      "source": [
        "df = df[df['pickup_latitude'] <=np.percentile(df.pickup_latitude,99.8) ] #filtering records \n",
        "df = df[df['pickup_latitude']>=np.percentile(df.pickup_latitude,1) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBr4AbSlxCi-"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SodBLs6X-Vo"
      },
      "source": [
        "Removing Outliers from pickup_longitude and pickup latitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eECOnpOVXuVi"
      },
      "outputs": [],
      "source": [
        "percentile_speed = [1, 25, 50, 75, 95, 99, 99.8]\n",
        "print(\"Total number of trips = {:,}\".format(len(df)))\n",
        "for i in percentile_speed:\n",
        "    print(\"{}% of the longitude were below {:.2f} degree\".format(i, np.percentile(df.pickup_longitude, i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwGfV7AwiVIc"
      },
      "outputs": [],
      "source": [
        "df = df[df['pickup_longitude'] <=np.percentile(df.pickup_longitude,99.8) ] #filtering records \n",
        "df = df[df['pickup_longitude']>=np.percentile(df.pickup_longitude,1) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6NvQ1aMLI5P"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rvPYy0BxIPz"
      },
      "source": [
        "Removing Outliers from trip_duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubCybt-CxSmA"
      },
      "outputs": [],
      "source": [
        "percentile_trip_duration = [1, 25, 50, 75, 95, 99, 99.8]\n",
        "print(\"Total number of trips = {:,}\".format(len(df)))\n",
        "for i in percentile_trip_duration:\n",
        "    print(\"{}% of the trips were below {:.2f} seconds\".format(i, np.percentile(df.trip_duration, i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe-0V_5viuve"
      },
      "outputs": [],
      "source": [
        "df = df[df['trip_duration'] <= np.percentile(df.trip_duration,99.8)] #filtering records \n",
        "df = df[df['trip_duration'] >=np.percentile(df.trip_duration,1) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNCT0oppxagO"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nct85peKxfTK"
      },
      "source": [
        "Removing Outliers from distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pysAXWz1xokD"
      },
      "outputs": [],
      "source": [
        "percentile_trip_duration = [1, 25, 50, 75, 95, 99, 99.8]\n",
        "print(\"Total number of trips = {:,}\".format(len(df)))\n",
        "for i in percentile_trip_duration:\n",
        "    print(\"{}% of the distance were below {:.2f} km\".format(i, np.percentile(df.distance, i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y2KENn4j9_r"
      },
      "outputs": [],
      "source": [
        "df = df[df['distance'] <= np.percentile(df.distance,99.8)] #filtering records \n",
        "df = df[df['distance'] >= np.percentile(df.distance,1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39wEpbJAxzwC"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0SS0Pgg_Hjn"
      },
      "source": [
        "Removing Outliers from trip_speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy7HmxV-_E_p"
      },
      "outputs": [],
      "source": [
        "percentile_trip_duration = [1, 25, 50, 75, 95, 99, 99.8]\n",
        "print(\"Total number of trips = {:,}\".format(len(df)))\n",
        "for i in percentile_trip_duration:\n",
        "    print(\"{}% of the speed were below {:.2f} mph\".format(i, np.percentile(df.trip_speed, i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C0gi7-f_WY3"
      },
      "outputs": [],
      "source": [
        "df.trip_speed.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz2RNQen_cJH"
      },
      "outputs": [],
      "source": [
        "df.trip_speed.max() #practically not possible in nyc busy city roads ,its a outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlZcbLAVnUy7"
      },
      "outputs": [],
      "source": [
        "df = df[df['trip_speed'] <= np.percentile(df.trip_speed,99.8)] #filtering records \n",
        "df = df[df['trip_speed'] >= np.percentile(df.trip_speed,1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLHh29KZAIpU"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92D4CFqHOH3u"
      },
      "outputs": [],
      "source": [
        "df.drop(labels='id',inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEZSY7-HNgHb"
      },
      "outputs": [],
      "source": [
        "categorical_features=df.describe(include='object').columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Okpag_zTN1Vi"
      },
      "outputs": [],
      "source": [
        "categorical_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzIlp2gJNd6b"
      },
      "outputs": [],
      "source": [
        "for col in categorical_features:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    df.boxplot(column ='trip_duration', by = col, ax = ax)\n",
        "    ax.set_title('Label by ' + col)\n",
        "    ax.set_ylabel(\"trip_duration\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyQlW1mfAfgU"
      },
      "source": [
        "Intially we had 1,458,644 records and after data cleaning by removing outliers we finally left with 1,373,783 records and added few additional features. Nearly 84,861 records were irrelavent to our problem statement and after data cleaning now we can start with our exploratory data analysis part ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdRzjodtcpkd"
      },
      "source": [
        "#4.Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rfUT6uE80qs"
      },
      "source": [
        "##Univariate Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "matt1AvVFfAF"
      },
      "source": [
        "##Passenger count feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGwmsnPraP-V"
      },
      "outputs": [],
      "source": [
        "ax = sns.countplot(x = df['passenger_count'])\n",
        "plt.title(' Dist of passenger count')\n",
        "\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(x = p.get_x() + (p.get_width()/2),\n",
        "    y = height+0.2, ha = 'center', s = '{:.0f}'.format(height))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA6dH-0gD1zR"
      },
      "outputs": [],
      "source": [
        "df=df[df['passenger_count']!=0]  #remove the rows which have 0 or 7 or 9 passenger count.\n",
        "df=df[df['passenger_count']<=6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6lbjoyW89NO"
      },
      "source": [
        "The above plot tells us that the mostly  the taxi trip passengers count is one.\n",
        "\n",
        "It depicts that taxi are mostly prefered by those who likes to travel alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvP7Eq-u9wo2"
      },
      "source": [
        "##pickup/dropoff day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntwe54pzaXHZ"
      },
      "outputs": [],
      "source": [
        "figure, ax = plt.subplots(nrows = 1, ncols=2, figsize = (15,10))\n",
        "sns.countplot(x = 'pickup_day', data = df, ax = ax[0])\n",
        "ax[0].set_title(' no of pickups done on each day of the week')\n",
        "\n",
        "sns.countplot(x = 'dropoff_day', data = df, ax = ax[1])\n",
        "ax[1].set_title(' no of dropoffs done on each day of the week')\n",
        "\n",
        "#plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr90cKIv991m"
      },
      "source": [
        "The plot tells us that mostly on friday's we can see a high demand for taxi trip and the least number of taxi trip demand on Monday."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-cXKNyL8KbL"
      },
      "source": [
        "##pickup_timezone "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxlnnzxCdh1p"
      },
      "outputs": [],
      "source": [
        "ax = sns.countplot(x=df['pickup_timezone']);\n",
        "plt.title('Distribution of pickup_timezone')\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(x = p.get_x()+(p.get_width()/2), # x-coordinate position of data label, padded to be in the middle of the bar\n",
        "    y = height+0.2, ha = 'center',s = '{:.0f}'.format(height)) # data label, formatted to ignore decimals\n",
        "    #ha = ‘center’) # sets horizontal alignment (ha) to center\n",
        "plt.xticks(rotation = 'vertical')    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwevPHfM8Z7i"
      },
      "source": [
        "1. The high demand for taxi trip is in the evening timezone.\n",
        "2. The least demand for taxi trip is in the afternoon timezone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2o2FWo_6g0m"
      },
      "source": [
        "##pickup_hour and drop off hour "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nce0rNADeBLx"
      },
      "outputs": [],
      "source": [
        "figure, ax = plt.subplots(nrows = 1, ncols=2, figsize = (10,5))\n",
        "\n",
        "\n",
        "df.pickup_hour.hist(bins = 24, ax = ax[0])\n",
        "ax[0].set_title(' pickup hrs')\n",
        "\n",
        "\n",
        "df.dropoff_hour.hist(bins = 24, ax = ax[1])\n",
        "ax[1].set_title('dropoff hours')\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjwZziwZ_r2B"
      },
      "outputs": [],
      "source": [
        "df['pickup_hour'].replace(to_replace=0,value=24,inplace=True) #replacing 0 hr with 24 hr "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpuiRHMBecKj"
      },
      "outputs": [],
      "source": [
        "ax = sns.countplot(x = df['pickup_hour'])\n",
        "plt.title('total pickup_hour')\n",
        "\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(x = p.get_x() + (p.get_width()/2),\n",
        "    y = height+0.2, ha = 'center', s = '{:.0f}'.format(height))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaZPIU2nCmkc"
      },
      "source": [
        "We see the busiest hours are 6:00 pm to 7:00 pm and that makes sense as this is the time when people return from their offices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2pa8Rt66qFh"
      },
      "source": [
        "1. The most busy hours  for taxi trip were between evening 18-22 hr\n",
        "2. The least busy hours were between early morning 2-5 hr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYrsOYmX59aw"
      },
      "source": [
        "##pickup/dropoff_month "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB5RRODres5_"
      },
      "outputs": [],
      "source": [
        "ax = sns.countplot(x = df['pickup_month'])\n",
        "plt.title(' Distribution of  pick month')\n",
        "\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(x = p.get_x() + (p.get_width()/2),\n",
        "    y = height+0.2, ha = 'center', s = '{:.0f}'.format(height))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4wwtGCle7JE"
      },
      "outputs": [],
      "source": [
        "ax = sns.countplot(x = df['dropoff_month'])\n",
        "plt.title(' Distribution of total dropoff month')\n",
        "\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(x = p.get_x() + (p.get_width()/2),\n",
        "    y = height+0.2, ha = 'center', s = '{:.0f}'.format(height))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRX-ENgq5AAj"
      },
      "source": [
        "1.The month of March has received the highest number of trips followed by April for both pickup/dropoff.\n",
        "\n",
        "2.The least number of trips done in the month of January and July. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A4QKByaFNGU"
      },
      "source": [
        "##Bivariate  Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwvGxlteGCNZ"
      },
      "source": [
        "##Passenger Count and Vendor id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0xK-MsHGGGV"
      },
      "outputs": [],
      "source": [
        "sns.barplot(y='passenger_count',x='vendor_id',data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_P_K0SPGRrG"
      },
      "source": [
        "This shows that vendor 2 generally carries 2 passengers while vendor 1 carries 1 passenger rides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D1n6mxuJOUb"
      },
      "source": [
        "##Trip Duration per time zone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzuviJguIYSG"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(x='pickup_timezone',y='trip_duration',data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsMwBTfbJCOU"
      },
      "source": [
        "From the above lineplot we can say that, trip duration is the maximum in the afternoon and lowest between late night and morning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIUeN6g-JfoO"
      },
      "source": [
        "##Trip Duration per different days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H79bsCG4Jahw"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(x='pickup_day',y='trip_duration',data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThwAs0jAJr3Q"
      },
      "source": [
        "From the above line plot we can say that,the trip duration is the maximum in Wednesday and lowest on Sunday"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWlJjsGFG027"
      },
      "source": [
        "##Number of trips per day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNFspkvdGtDH"
      },
      "outputs": [],
      "source": [
        "df.groupby(df.pickup_datetime.dt.date).size().plot()\n",
        "plt.title('Count of rides per day')\n",
        "plt.ylabel('Count of rides per day')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSYJVECtHAcK"
      },
      "source": [
        "The number of rides per day is cyclical with a dip in the rides during the night time.\n",
        "\n",
        "The sudden dip in the taxi rides between the 20th and 26th Jan was because of the heavy snow that was observed during that period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkysMqQA872l"
      },
      "source": [
        "##Plotting average trip duration for each hour over the entire year and the average number of rides per hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M69cc3zHRL9"
      },
      "outputs": [],
      "source": [
        "#Plotting average trip duration for each hour over the entire year\n",
        "ax1 = plt.subplot(211)\n",
        "df.groupby(df.pickup_hour)['trip_duration'].mean().plot(ax = ax1, figsize=(10,6))\n",
        "plt.ylabel('Trip duration in seconds')\n",
        "plt.xticks(df.pickup_hour.unique())\n",
        "plt.title('Trip duration in seconds averaged over hours in the year of 2016')\n",
        "\n",
        "# Plotting the average number of rides per hour\n",
        "ax2 = plt.subplot(212)\n",
        "df.groupby(['pickup_date', \n",
        "                    'pickup_hour']).count()['vendor_id'].groupby('pickup_hour').mean().plot(ax = ax2, figsize=(10,6))\n",
        "plt.ylabel('Average count of pickups per hour')\n",
        "plt.xticks(df.pickup_hour.unique())\n",
        "plt.title('Average count of pickups per hour in the year of 2016')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UQIaaY7Hkn2"
      },
      "source": [
        "Note: Please notice that the y-axis doesn't start at 0.\n",
        "\n",
        "As one would expect the trip duration and the number of rides are higher in the evening time. As the number of rides go up in a certain area one can expect the resulting traffic to slow down the traffic increasing the trip duration time.\n",
        "\n",
        "From the 2nd plot we can see how the pickup rides increase steadily from 5am to 8am only to flatten out between 8am to 4pm and then again steeply increase from 4pm to 6pm to fall down later.\n",
        "\n",
        "The average trip duration is around 15 minutes during the evening time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b-GGsEAUL6T"
      },
      "source": [
        "## Finding correlation in variables (both dependent and independent, Visualizations on data using Heat Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHsV0Z1sIWBd"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frcCUR4xImCS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqXU-c_vljhd"
      },
      "outputs": [],
      "source": [
        " ## Correlation\n",
        "plt.figure(figsize=(15,8))\n",
        "correlation=df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sEiuRl4UsBm"
      },
      "source": [
        "1. We can see a high correlation between pickup_month and dropoff_month,pickup_date and dropoff_date,pickup_weekday and dropoff_weekday.\n",
        "2. Our target variable shows 0.78 percent correalation with distance.\n",
        "3. pickup_hour and dropoff hour shows a correaltion of 0.68.\n",
        "4. we drop time_diff_minutes since its highly correalted with trip_duration.\n",
        "5. In all highly correalted features  we can only keep the pickup details and drop the dropoff details to remove multicollinearity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D-Dpbg0I1NG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rrJlJmmlpok"
      },
      "outputs": [],
      "source": [
        "#Multicollinearity\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJVl0erwl9bz"
      },
      "outputs": [],
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i  in [\n",
        " 'passenger_count',\n",
        " 'pickup_weekday',\n",
        " 'pickup_hour',\n",
        " 'pickup_month',\n",
        " 'pickup_date','distance',\n",
        " 'trip_direction']]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeFVPO76rSeO"
      },
      "source": [
        "#5.Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipwsItyTAcs0"
      },
      "source": [
        "# Multivariate Normality Distribution check and Handling Skewness\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrPqI4_gTJmg"
      },
      "outputs": [],
      "source": [
        "#  Check the distribution and handle the skewnwss if present\n",
        "# Trip_Duration (Target Variable)\n",
        "plt.figure(figsize=(10,15))\n",
        "sns.distplot(df['trip_duration'])\n",
        "plt.xlabel('trip_duration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTUMN_1uAhXC"
      },
      "outputs": [],
      "source": [
        "#Using log transform to bring it to normal distribution\n",
        "plt.figure(figsize=(10,15))\n",
        "sns.distplot(np.log(df['trip_duration']))\n",
        "plt.xlabel('trip_duration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFLhqbwNSm4w"
      },
      "outputs": [],
      "source": [
        "numeric_features=df.describe().columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma5hlW4mSwoi"
      },
      "outputs": [],
      "source": [
        "numeric_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eizf6G68UT8U"
      },
      "outputs": [],
      "source": [
        "# plot a bar plot for each numerical features\n",
        "\n",
        "for col in numeric_features:\n",
        "  fig = plt.figure(figsize=(9, 6))\n",
        "  ax = fig.gca()\n",
        "  feature = df[col]\n",
        "  feature.hist(bins=50, ax = ax)\n",
        "  ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)    \n",
        "  ax.set_title(col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V0b1nVhke0u"
      },
      "source": [
        "Treating the skewness in the distance feature using log transform.\n",
        "\n",
        "trip_speed,time_diff_minutes features are highly in correaltion with our target variable and it may result in data leakage and getting high accuracy near to 100 percentage hence we will not handle the skewness in these features and directly drop these features before model buliding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYtevuveUtEi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,15))\n",
        "sns.distplot(np.log(df['distance']))\n",
        "plt.xlabel('distance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiZmcKD6gwsN"
      },
      "source": [
        "# Check for Linearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENkLzE21TAGy"
      },
      "outputs": [],
      "source": [
        "for col in numeric_features[:]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = df[col]\n",
        "    label = df['trip_duration']\n",
        "    correlation = feature.corr(label)\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('trip_duration')\n",
        "    ax.set_title('trip_duration vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(df[col], df['trip_duration'], 1)\n",
        "    y_hat = np.poly1d(z)(df[col])\n",
        "\n",
        "    plt.plot(df[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDTodqsRpyXy"
      },
      "source": [
        "From above plot we can conclude that only trip_distance and trip_speed were having a linear relationship with trip_duration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7WDX-Res9pe"
      },
      "source": [
        "# Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkr_RNkiiM7c"
      },
      "outputs": [],
      "source": [
        "df_copy = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoi537IMqttc"
      },
      "outputs": [],
      "source": [
        "df_copy.drop(labels=['dropoff_timezone','store_and_fwd_flag',],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx9cifncubN1"
      },
      "outputs": [],
      "source": [
        "# One hot encoding on pickup_timezone feature\n",
        "df_copy = pd.get_dummies(df_copy,columns=[\"pickup_timezone\"],prefix=[\"pickup_timezone\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GnBBRGvw_cr"
      },
      "outputs": [],
      "source": [
        "df_copy.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW9wQtaiUqtK"
      },
      "source": [
        "Handling Skewness in numerical features using log Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SFL-e0ch5B9"
      },
      "outputs": [],
      "source": [
        "df_copy['distance'] = df_copy['distance'].map(lambda x : np.log(x) if x != 0 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Lf6gA2o7tSS"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_copy['pickup_month'] = df_copy['pickup_month'].map(lambda x : np.log(x) if x != 0 else 0)\n",
        "df_copy['pickup_hour'] = df_copy['pickup_hour'].map(lambda x : np.log(x) if x != 0 else 0)\n",
        "df_copy['passenger_count'] = df_copy['passenger_count'].map(lambda x : np.sqrt(x) if x != 0 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUkbwo-NapCB"
      },
      "outputs": [],
      "source": [
        "df_copy.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLlOk98FH414"
      },
      "source": [
        "#6.Feature Selection\n",
        "\n",
        "We cannot use all the columns from the dataframe because some of them are datetime and some of them were calculated based on the target variable such as trip_speed_mph.\n",
        "\n",
        "So, we will use only the following columns:\n",
        "cols_to_use = ['vendorid', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'pickup_month', 'pickup_weekday', 'pickup_hour', 'distance, 'trip_direction',  'trip_duration']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "462sHYFCIBT7"
      },
      "outputs": [],
      "source": [
        "features = ['vendor_id',\n",
        " 'passenger_count',\n",
        " 'pickup_longitude',\n",
        " 'pickup_latitude',\n",
        " 'dropoff_longitude',\n",
        " 'dropoff_latitude',\n",
        " 'pickup_weekday',\n",
        " 'pickup_hour',\n",
        " 'pickup_month',\n",
        " 'pickup_date','distance',\n",
        " 'trip_direction']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Koxryx_2NVFZ"
      },
      "outputs": [],
      "source": [
        "features.extend(['pickup_timezone_Afternoon', 'pickup_timezone_Evening',\n",
        "       'pickup_timezone_Late night', 'pickup_timezone_Morning'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRL0B96fNhtf"
      },
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yVOyJXbtSf_"
      },
      "outputs": [],
      "source": [
        "X = df_copy[features] #Independent features\n",
        "y = np.log(df_copy['trip_duration'])  #Dependent features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzCjPUN_abgI"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8bxlAGyocag"
      },
      "source": [
        "**Lets split the data into train and test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fUM_FlgoZk-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split( X,y , test_size = 0.2, random_state = 42) \n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MpzOi3FbrRK"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc= StandardScaler()\n",
        "X_train[features]=sc.fit_transform(X_train[features])\n",
        "X_test[features]=sc.transform(X_test[features])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoRxQYJ1B4oK"
      },
      "source": [
        "#Buliding a base model using Linear Regression \n",
        "We have many variables such as the pickup/dropoff month, weekday, hour of the day, trip direction which are not linear variables and can be difficult for a linear regression (LR) algorithm to model without first converting these variables to appropriate forms that can be fed to the LR models and understood by it. And, we also need to scale the data to prevent the dominance of larger magnitude variables in LR models.\n",
        "\n",
        "Another alternative is we can use non-linear methods such as decision trees to fit the data. Decision tree doesn’t require us to convert the variables because it can split across any values of the variables and also, we don’t need to scale the data when using trees because each variable is considered separately for calculating the gain at each branching.\n",
        "\n",
        "But before moving onto decision trees or random forest let’s check the performance of LR using only few significant variables which have vif values below 5,hence there will be no multicollinearirty \n",
        "\n",
        "We have to satisfy linear regression assumption inorder to use a linear regression model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msee9B8LTCb0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsiheyarTC2v"
      },
      "outputs": [],
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i  in [\n",
        " 'passenger_count',\n",
        " 'pickup_weekday',\n",
        " 'pickup_hour',\n",
        " 'pickup_month',\n",
        " 'pickup_date','distance',\n",
        " 'trip_direction']]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Oz0YVwAQkCm"
      },
      "outputs": [],
      "source": [
        "features1= [\n",
        " 'passenger_count',\n",
        " 'pickup_weekday',\n",
        " 'pickup_hour',\n",
        " 'pickup_month',\n",
        " 'pickup_date','distance','trip_direction'\n",
        " ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6kPpmfLQxA1"
      },
      "outputs": [],
      "source": [
        "features1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo_hFAwIBl5w"
      },
      "outputs": [],
      "source": [
        "X1 = df_copy[features1] #Independent features\n",
        "y1 = np.log(df_copy['trip_duration'])  #Dependent features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiXqZViSoMcI"
      },
      "source": [
        "#7.Model Buliding\n",
        "Linear regression (with only few variables), Decision Tree, Random Forest and XGBoost were fit on the NYC taxi trip data with additional features added from the EDA notebook. For training, only a small sample (500,000) of the ~4.2M trips was used but the best model was tested on the entire dataset to verify that the training sample was selected randomly and represents the entire dataset indeed.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o25hsrUwBhH2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split( X1,y1 , test_size = 0.2, random_state = 42) \n",
        "print(X1_train.shape)\n",
        "print(X1_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pOZV2ONByhF"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc= StandardScaler()\n",
        "X1_train[features1]=sc.fit_transform(X_train[features1])\n",
        "X1_test[features1]=sc.transform(X_test[features1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjAokZK9CqhR"
      },
      "outputs": [],
      "source": [
        "reg = LinearRegression().fit(X1_train, y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5TVy81QCshH"
      },
      "outputs": [],
      "source": [
        "reg.score(X1_train, y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbSP4PfMrMCI"
      },
      "outputs": [],
      "source": [
        "reg.coef_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeJuoO59rSJ9"
      },
      "outputs": [],
      "source": [
        "reg.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXnCKxA-rXZ3"
      },
      "outputs": [],
      "source": [
        "# Predicting the Test set results using training data\n",
        "y_pred_train = reg.predict(X1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGsO1ViIrZx2"
      },
      "outputs": [],
      "source": [
        "y_pred_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VdcNnoErhZq"
      },
      "source": [
        "## 8.**Regression Evaluation Metrics**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Comparing these metrics:\n",
        "\n",
        "MAE is the easiest to understand, because it's the average error.\n",
        "<br>MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
        "<br>RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
        "<br>All of these are loss functions, because we want to minimize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBOHoExtrdhk"
      },
      "outputs": [],
      "source": [
        "# Predicting the Test set results using test data\n",
        "y_pred_test = reg.predict(X1_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzAY1IABrmwA"
      },
      "outputs": [],
      "source": [
        "y_pred_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApuboJUkVLjb"
      },
      "outputs": [],
      "source": [
        "# Test performance using Evaluation metrics\n",
        "MSE  = mean_squared_error((y_test), (y_pred_test))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "MAE=mean_absolute_error((y_test), (y_pred_test))\n",
        "print(\"MAE :\" ,MAE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score((y_test), (y_pred_test))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_pred_test)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdbhLaVuWBLx"
      },
      "source": [
        "#Plotting a Scatter plot on Actual vs Predicted trip duration Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EPnyonsV0em"
      },
      "outputs": [],
      "source": [
        "plt.scatter((y_test), (y_pred_test))\n",
        "plt.xlabel('Actual trip duration')\n",
        "plt.ylabel('Predicted trip duration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5_djIsfWUy2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.plot((y_pred_test))\n",
        "plt.plot(np.array((y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDP4YQM7WrbG"
      },
      "source": [
        "If we see above graph our prediction is quiet good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng-S3c_7WzJd"
      },
      "source": [
        "# **Residuals:**\n",
        "\n",
        "---\n",
        "A residual is the vertical distance between a data point and the regression line. Each data point has one residual. They are positive if they are above the regression line and negative if they are below the regression line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmoIz7mPWlYH"
      },
      "outputs": [],
      "source": [
        "fig=plt.figure(figsize=(8,8))\n",
        "  \n",
        "sns.distplot(((y_test)- (y_pred_test)),bins=20)\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I4fm0WfXD_k"
      },
      "outputs": [],
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_test),(y_test)-(y_pred_test))\n",
        "plt.xlabel('Predicted trip_duration')\n",
        "plt.ylabel('residuals')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBQnK7HnwY5D"
      },
      "source": [
        "## **Implementing Lasso regression**\n",
        "\n",
        "---\n",
        "Lasso regression is a type of linear regression that uses shrinkage. Shrinkage is where data values are shrunk towards a central point, like the mean. The lasso procedure encourages simple, sparse models (i.e. models with fewer parameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4ta_wsewdC8"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso  = Lasso(alpha=0.005 , max_iter= 3000)\n",
        "\n",
        "lasso.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOFm73JgwqE0"
      },
      "outputs": [],
      "source": [
        "lasso.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FrH88vWxaZf"
      },
      "outputs": [],
      "source": [
        "y_pred_l = lasso.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhwmkYg-xcQc"
      },
      "outputs": [],
      "source": [
        "MSE  = mean_squared_error((y_test), (y_pred_l))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "MAE=mean_absolute_error((y_test), (y_pred_l))\n",
        "print(\"MAE :\" ,MAE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score((y_test), (y_pred_l))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_pred_l)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U41oUijYZiD"
      },
      "outputs": [],
      "source": [
        "plt.scatter((y_test), (y_pred_l))\n",
        "plt.xlabel('Actual trip duration')\n",
        "plt.ylabel('Predicted trip duration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrpc98dQYqDx"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.plot((y_pred_l))\n",
        "plt.plot(np.array((y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee2S01PMY03O"
      },
      "outputs": [],
      "source": [
        "#Resuldual Analysis\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "  \n",
        "sns.distplot(((y_test)- (y_pred_l)),bins=20,color='r')\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYK4fwKMY-6o"
      },
      "outputs": [],
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_l),(y_test)-(y_pred_l),c='r')\n",
        "plt.xlabel('Predicted trip duration')\n",
        "plt.ylabel('residuals')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSogUt8tyZqm"
      },
      "source": [
        "#Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kPk-haKyZVE"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge  = Ridge(alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAE84Kn6ygCk"
      },
      "outputs": [],
      "source": [
        "ridge.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj2Fzz_gyjBG"
      },
      "outputs": [],
      "source": [
        "ridge.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg5CaKWnylW6"
      },
      "outputs": [],
      "source": [
        "y_pred_r = ridge.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf6gd4OZyusr"
      },
      "outputs": [],
      "source": [
        "MSE  = mean_squared_error((y_test), (y_pred_r))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "MAE=mean_absolute_error((y_test), (y_pred_r))\n",
        "print(\"MAE :\" ,MAE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score((y_test), (y_pred_r))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_pred_r)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wabmKnvsZa-V"
      },
      "outputs": [],
      "source": [
        "plt.scatter((y_test), (y_pred_r))\n",
        "plt.xlabel('Actual trip duration')\n",
        "plt.ylabel('Predicted trip duration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyYma5H7ZmN2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.plot((y_pred_r))\n",
        "plt.plot((np.array(y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6IYZEmcZuN0"
      },
      "outputs": [],
      "source": [
        "#Resuldual Analysis\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "  \n",
        "sns.distplot(((y_test)- (y_pred_r)),bins=20,color='r')\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOWhsWmmZ1f4"
      },
      "outputs": [],
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_r),(y_test)-(y_pred_r),c='r')\n",
        "plt.xlabel('Predicted trip duration')\n",
        "plt.ylabel('residuals')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-O1oJpzTMmH"
      },
      "source": [
        "#Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNpITpOLTP0g"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKxbsbGrTdhg"
      },
      "outputs": [],
      "source": [
        "des_regressor = DecisionTreeRegressor(random_state=10)\n",
        "cross_val_score(des_regressor, X_train, y_train, cv=5).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiXUb3cepHXB"
      },
      "outputs": [],
      "source": [
        "des_regressor.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIhOyDVBT0YN"
      },
      "outputs": [],
      "source": [
        "y_pred_des = des_regressor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-sxa3VsaOTq"
      },
      "outputs": [],
      "source": [
        "#Evaluating the model using regression metrics\n",
        "MSE  = mean_squared_error((y_test), (y_pred_des))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "MAE=mean_absolute_error((y_test), (y_pred_des))\n",
        "print(\"MAE :\" ,MAE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score((y_test), (y_pred_des))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_pred_des)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N538XoT8apil"
      },
      "outputs": [],
      "source": [
        "#Scatter plot vs Actual & Predicted trip duration Values\n",
        "plt.scatter((y_test), (y_pred_des))\n",
        "plt.xlabel('Actual trip duration')\n",
        "plt.ylabel('Predicted trip duration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd-zQW58at1S"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.plot((y_pred_des))\n",
        "plt.plot((np.array(y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMEfLdwKmJMl"
      },
      "source": [
        "\n",
        "\n",
        "We have used RandomForest Ensemble Algo (bagging) and Xgboost Ensemble Algo(boosting) techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rXe3yMbbLe7"
      },
      "source": [
        "#Random Forest\n",
        "Using RandomForest Ensemble technique to predict the trip_duration after applying hyperparameter tuning with help of RandomSearchcv (cross-validation technique)\n",
        "Max depth and n estimator were the parameters we have selected with crossvalidation value 3 because if we add more parameters it will take  high computation time. \n",
        "\n",
        "It nearly took us 1.5hrs to run this Randomizedsearchcv hyperparameter tunning,so adding more parameters and cv value will increase time complexity.\n",
        "\n",
        "So this hyperparameter tunning can be improved with adding more parameters and crossvalidation score to 5 or more to get a more refined model.We can also use Gridsearchcv for hyperparameter tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKFfOoHqbb1q"
      },
      "outputs": [],
      "source": [
        "#importing reqd libraries\n",
        "from sklearn.ensemble import RandomForestRegressor "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvOGFmiadrDx"
      },
      "outputs": [],
      "source": [
        "rf= RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hwy0ex0d5UO"
      },
      "outputs": [],
      "source": [
        "#Setting various parameter for hyperparameter tuning\n",
        "param_dict_rf = {\n",
        "    'max_depth': [4, 6, 8],\n",
        " 'n_estimators': [80, 100]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsOJ2zjcfdOr"
      },
      "outputs": [],
      "source": [
        "rf_random = RandomizedSearchCV(estimator=rf,\n",
        "                       param_distributions = param_dict_rf,\n",
        "                       cv = 3, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g1U1AScjpp9"
      },
      "source": [
        "Fitting the model to train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w_8E5_Ip-N4_"
      },
      "outputs": [],
      "source": [
        "rf_random.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XhqjNEFNfgtY"
      },
      "outputs": [],
      "source": [
        "# print the best parameters after cross validation\n",
        "print(rf_random.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yrZQQfRNfjwe"
      },
      "outputs": [],
      "source": [
        "print('Train  neg_mean_squared_error score : ', rf_random.best_estimator_.score(X_train,y_train))\n",
        "print('Test neg_mean_squared_error score: ', rf_random.best_estimator_.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SUHVXvg7ZDQt"
      },
      "outputs": [],
      "source": [
        "y_pred_rf = rf_random.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x5fMiR46BdYh"
      },
      "outputs": [],
      "source": [
        "#Evaluating the model using regression metrics\n",
        "MSE  = mean_squared_error((y_test), (y_pred_rf))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "MAE=mean_absolute_error((y_test), (y_pred_rf))\n",
        "print(\"MAE :\" ,MAE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score((y_test), (y_pred_rf))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_pred_rf)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkspcjL0hPmt"
      },
      "source": [
        "#XGBOOST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3lAb4r3iKk9"
      },
      "source": [
        "Using XGboost Ensemble technique to predict the trip_duration after applying hyperparameter tuning with help of RandomSearchcv (cross-validation technique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UriBqfnqiKzm"
      },
      "outputs": [],
      "source": [
        "#importing reqd libraries\n",
        "import xgboost as xg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QrWDUbT1hd-9"
      },
      "outputs": [],
      "source": [
        "xgb = xg.XGBRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jlc5nGuPivt0"
      },
      "outputs": [],
      "source": [
        "#Setting various parameter for hyperparameter tuning\n",
        "param_dict_xgb = {\n",
        "    'max_depth': [4, 6, 8],\n",
        " 'n_estimators': [60, 100]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "daPK7KXXhEsK"
      },
      "outputs": [],
      "source": [
        "xgb_random = RandomizedSearchCV(estimator=xgb,\n",
        "                       param_distributions = param_dict_xgb,\n",
        "                       cv = 5, verbose=2)\n",
        "\n",
        "xgb_random.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P1LZ0MMXoHjC"
      },
      "outputs": [],
      "source": [
        "# print the best parameters after cross validation\n",
        "xgb_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZHcQEL06oS_I"
      },
      "outputs": [],
      "source": [
        "print('Train neg_mean_squared_error score score : ', xgb_random.best_estimator_.score(X_train,y_train))\n",
        "print('Test neg_mean_squared_error score score : ', xgb_random.best_estimator_.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pB-HpD5FZgyS"
      },
      "outputs": [],
      "source": [
        "y_pred_xg = xgb_random.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PaN6iPVopprG"
      },
      "outputs": [],
      "source": [
        "#Evaluating the model using regression metrics\n",
        "MSE  = mean_squared_error((y_test), (y_pred_xg))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "MAE=mean_absolute_error((y_test), (y_pred_xg))\n",
        "print(\"MAE :\" ,MAE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score((y_test), (y_pred_xg))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_pred_xg)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4qR3gJKOYBQ"
      },
      "source": [
        "#Comparing negative mean square error in different models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpjxWF8B9yOQ"
      },
      "outputs": [],
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.datasets import make_regression\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_regression(n_samples=1000, n_features=10, n_informative=15, random_state=1)\n",
        "\treturn X, y\n",
        " \n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['Ridge'] = Ridge()\n",
        "\tmodels['Lasso'] = Lasso()\n",
        "\tmodels['DecisionTree'] = DecisionTreeRegressor()\n",
        "\tmodels['Random_forest'] = RandomForestRegressor()\n",
        "\tmodels['XGBoost'] = xg.XGBRegressor()\n",
        "\n",
        "\treturn models\n",
        " \n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv =  RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        " \n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca5Iw0yQO0pB"
      },
      "source": [
        "# . Conclusion\n",
        "\n",
        "\n",
        "\n",
        "1.Our base model (Linear Regression) gave us a r2_score of 0.67 in train and test data and keep this model accuracy in reference to compare other model.\n",
        "\n",
        "2.We got the best model accuracy in Xgboost model,r2 score of 0.84 in training set and 0.83 in test data..The RMSE score of Xgboost model is 0.282\n",
        "\n",
        "3.Our second best model is  RandomForestbased with a r2 score of 0.7485 accuracy in training and 0.7475 accuracy in test data. The RMSE score of random forest is 0.350\n",
        "\n",
        "4.Decision Tree has given us least score in evaluation compared to all other algorithms based on negative mean absloute error and r2 score.\n",
        "\n",
        "\n",
        "5.We just used ensemble techniques over here to demonstrate various other options for these kind of regression problems and to make the project little bit more informative.\n",
        "\n",
        "6.We can also do Model Explainability  of random forest and Xgboost model over here using SHAP or LIME .But our team intention was not to make it more lengthy hence we restricted ourseleves till here. \n",
        "\n",
        "7.results in ridge and lasso regularized linear regression algorithm based on negative mean absoulte error is good compared to other models\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tOGC-qoyhJeX",
        "yx1hnX2NDfwr",
        "cYB0sdRwFSjH",
        "M2yK4T4-yjLY",
        "z_xrfuhgps2k",
        "xNxCjCIop8QC",
        "7xFtCdDstMzW",
        "Smo6OpP2uPcK",
        "wyTc54l0DmSB",
        "FpgcSnff0u6o",
        "AuiqsL2Xv5Y5",
        "4QN7knfiNMZL",
        "i_nBphJJBz7L",
        "MdRzjodtcpkd",
        "ipwsItyTAcs0",
        "hiZmcKD6gwsN",
        "i7WDX-Res9pe",
        "eLlOk98FH414",
        "SoRxQYJ1B4oK",
        "hiXqZViSoMcI",
        "pdbhLaVuWBLx",
        "ng-S3c_7WzJd",
        "XBQnK7HnwY5D",
        "PSogUt8tyZqm",
        "f-O1oJpzTMmH",
        "8rXe3yMbbLe7",
        "FkspcjL0hPmt",
        "W4qR3gJKOYBQ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}